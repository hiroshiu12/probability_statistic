{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use gensim to obtain \"bag-of-words\" representation?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just practice of <https://radimrehurek.com/gensim/tut1.html>. And reminder for me :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim import matutils\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\"Membership of the club has dwindled from 70 to 20\",\n",
    "         \"They tried to buffer themselves against problems and unvertainties\",\n",
    "         \"I don't want to be just a cog in the wheel anymore\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First of all, you have to tokenize corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_toknizer(corpus):\n",
    "    \"\"\"\n",
    "    Parameter :\n",
    "    -------------------\n",
    "    corpus :  corpus should be corpus, list of sentences.\n",
    "    \"\"\"\n",
    "    token_list = []\n",
    "    for sentence in corpus:\n",
    "        token_list.append(sentence.split(' '))\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Membership', 'of', 'the', 'club', 'has', 'dwindled', 'from', '70', 'to', '20'], ['They', 'tried', 'to', 'buffer', 'themselves', 'against', 'problems', 'and', 'unvertainties'], ['I', \"don't\", 'want', 'to', 'be', 'just', 'a', 'cog', 'in', 'the', 'wheel', 'anymore']]\n"
     ]
    }
   ],
   "source": [
    "token_list = simple_toknizer(corpus)\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Next you have to create dictionary.\n",
    "*\"dictionary\"* is mapping between token and ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20': 9,\n",
       " '70': 7,\n",
       " 'I': 18,\n",
       " 'Membership': 0,\n",
       " 'They': 10,\n",
       " 'a': 23,\n",
       " 'against': 14,\n",
       " 'and': 16,\n",
       " 'anymore': 27,\n",
       " 'be': 21,\n",
       " 'buffer': 12,\n",
       " 'club': 3,\n",
       " 'cog': 24,\n",
       " \"don't\": 19,\n",
       " 'dwindled': 5,\n",
       " 'from': 6,\n",
       " 'has': 4,\n",
       " 'in': 25,\n",
       " 'just': 22,\n",
       " 'of': 1,\n",
       " 'problems': 15,\n",
       " 'the': 2,\n",
       " 'themselves': 13,\n",
       " 'to': 8,\n",
       " 'tried': 11,\n",
       " 'unvertainties': 17,\n",
       " 'want': 20,\n",
       " 'wheel': 26}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(token_list)\n",
    "# You can check the mapping by caling 'token2id' attribute.\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note :  \n",
    "You can mechanically filter some words out with **'filter_extremes'** and **'fileter_n_most_frequent'** methods.  \n",
    "Or you can specificly filter some words out with **'filter_tokens'**.  \n",
    "  \n",
    "As an example, filter numeric words from dictionary. They sometimes disrupt the model of machine learning or cluster..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number you wanna filter out is :  [7, 9]\n"
     ]
    }
   ],
   "source": [
    "# You must know the ids of word you want omit.\n",
    "regular_exp = re.compile('\\d+')\n",
    "ids_list = []\n",
    "for word, number in dictionary.token2id.items():\n",
    "    if regular_exp.match(word):\n",
    "        ids_list.append(number)\n",
    "\n",
    "print('The number you wanna filter out is : ',ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caution !  :  \n",
    "1. \"filter_tokens\" method modify mapping of itself. \n",
    "2. It changes ids of dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_tokens(bad_ids=ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 16,\n",
       " 'Membership': 0,\n",
       " 'They': 8,\n",
       " 'a': 21,\n",
       " 'against': 12,\n",
       " 'and': 14,\n",
       " 'anymore': 25,\n",
       " 'be': 19,\n",
       " 'buffer': 10,\n",
       " 'club': 3,\n",
       " 'cog': 22,\n",
       " \"don't\": 17,\n",
       " 'dwindled': 5,\n",
       " 'from': 6,\n",
       " 'has': 4,\n",
       " 'in': 23,\n",
       " 'just': 20,\n",
       " 'of': 1,\n",
       " 'problems': 13,\n",
       " 'the': 2,\n",
       " 'themselves': 11,\n",
       " 'to': 7,\n",
       " 'tried': 9,\n",
       " 'unvertainties': 15,\n",
       " 'want': 18,\n",
       " 'wheel': 24}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ids were changed.\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Now is the time to create bag of words representation with sparse vector.  \n",
    "  \n",
    "Contents of sparse vector is tuple which is (word id, the number of occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1)],\n",
       " [(2, 1),\n",
       "  (7, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector = [dictionary.doc2bow(tokens) for tokens in token_list] \n",
    "sparse_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. gensim has useful uitility to make dense vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can simply use matutils.corpus2dense to obtain dense vector, however don't forget let it know the number of dimention. Since dimentionality cannot be deduced from sparse vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vector= matutils.corpus2dense(sparse_vector,num_terms=len(dictionary.token2id))\n",
    "dense_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, mostly we use transposed version of that dense vector for machine learning or cluster or etc...  \n",
    "Therefore transposed vector is more useful :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vector.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
