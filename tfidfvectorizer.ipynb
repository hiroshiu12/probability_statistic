{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use tfidfvectorizer ?\n",
    "*\"tf-idf\"* is a numerical statistic that is intended to reflect how important a word is to a document in a corpus.　   \n",
    "source : <https://en.wikipedia.org/wiki/Tf%E2%80%93idf>  \n",
    "- *\"tf\"*  : the number of times each term occures in each document.  \n",
    "- *\"idf\"* : A measure of how much imformation the word provides.  \n",
    "\n",
    "There is really useful library which is \"tfidfvectorizer\" in scikit-learn to compute tf-idf value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm gonna compute *\"tf-idf\"* value of following corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = ['Seize the day!','Panic seized him','Police seized his device.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day', 'device', 'him', 'his', 'panic', 'police', 'seize', 'seized', 'the']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call constructer of tfidfvectorizer\n",
    "tfidf_ins = TfidfVectorizer()\n",
    "tfidf_ins.fit(corpus)\n",
    "# You can check \"vocabulary\" tfidfvectorizer holds.\n",
    "tfidf_ins.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ups ! The word \"seize\" seems not to be normalized...　Tf and idf of 'seize' and 'seized' should be computed as same words.  \n",
    "I think there are various type of normalization in Pyhon. However, this time, I specify vocabulary to constructor of corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary :  ['day', 'device', 'panic', 'police', 'seize', 'the']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['day', 'device', 'panic', 'police', 'seize', 'the']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = ['day','device','panic','police','seize','the']\n",
    "# You can specify vocabulary in constructer\n",
    "tfidf_ins2 = TfidfVectorizer(vocabulary=vocabulary)\n",
    "print('vocabulary : ',tfidf_ins2.vocabulary)\n",
    "\n",
    "tfidf_ins2.fit([document.replace('seized','seize') for document in corpus])\n",
    "tfidf_ins2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65249088,  0.        ,  0.        ,  0.        ,  0.38537163,\n",
       "         0.65249088],\n",
       "       [ 0.        ,  0.        ,  0.861037  ,  0.        ,  0.50854232,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.65249088,  0.        ,  0.65249088,  0.38537163,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = tfidf_ins2.transform([document.replace('seized','seize') for document in corpus])\n",
    "tfidf_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf of \"seize\"\n",
      "   (0, 0)\t0.385371627466\n",
      "  (1, 0)\t0.508542320378\n",
      "  (2, 0)\t0.385371627466\n",
      "tfidf of \"the\"\n",
      "   (0, 0)\t0.652490884513\n"
     ]
    }
   ],
   "source": [
    "print('tfidf of \"seize\"\\n',tfidf_vect[:,np.where(np.array(tfidf_ins2.get_feature_names())=='seize')[0][0]])\n",
    "print('tfidf of \"the\"\\n',tfidf_vect[:,np.where(np.array(tfidf_ins2.get_feature_names())=='the')[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"tfidfvectorizer\"* normalize each vector.  \n",
    "As you can see, the word 'seize' appear every documents, therefore the value of tfidf is lowest in each document.  \n",
    "However although the word 'the' seems to be useless to recognize semantic analysis, it has quite high value in document 1.  \n",
    "Hence I wanna register this word as a \"stop word\" :)  \n",
    "Actually there is already frozenset of stop-word in *\"sklearn.feature_extraction.text.ENGLISH_STOP_WORDS.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of presetted \"ENGLISH_STOP_WORDS :  318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of presetted \"ENGLISH_STOP_WORDS : ', len(text.ENGLISH_STOP_WORDS))\n",
    "# 'the' is already in \"ENGLISH_STOP_WORDS\"\n",
    "'the' in text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I wrote this cell, I notice that If you specify \"vocabulary\" in constructor, it seems to be prioritised than stop-word.  \n",
    "As a matter of fact, \"the\" was not excluded when vocabulary was specifid !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary :  None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['day', 'device', 'panic', 'police', 'seize']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify stop words to constructor\n",
    "# If you specify \"vocabulary\" in constructor, it seems to be prioritised.\n",
    "# As a matter of fact, \"the\" was not excluded when vocabulary was specifid.\n",
    "tfidf_ins_stop = TfidfVectorizer(analyzer='word',stop_words=text.ENGLISH_STOP_WORDS)\n",
    "print('vocabulary : ',tfidf_ins_stop.vocabulary)\n",
    "\n",
    "tfidf_ins_stop.fit([document.replace('seized','seize') for document in corpus])\n",
    "tfidf_ins_stop.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.861037  ,  0.        ,  0.        ,  0.        ,  0.50854232],\n",
       "       [ 0.        ,  0.        ,  0.861037  ,  0.        ,  0.50854232],\n",
       "       [ 0.        ,  0.65249088,  0.        ,  0.65249088,  0.38537163]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = tfidf_ins_stop.transform([document.replace('seized','seize') for document in corpus])\n",
    "tfidf_vect.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see understandable vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
